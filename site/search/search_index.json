{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to TinyMPC's documentation!","text":"<p>TinyMPC is a model-predictive controller built for robots with small amounts of computational power. It's lean and fast, allowing it to run on cheap microcontrollers that have limited memory and speed.</p> <p>Get Started  ICRA Paper  CDC Paper  Watch the Video </p>"},{"location":"#robot-demonstrations","title":"Robot Demonstrations","text":""},{"location":"#dynamic-obstacle-avoidance","title":"Dynamic obstacle avoidance","text":"<p>TinyMPC runs fast enough to enable re-linearizing constraints at each time step, allowing it to reason about moving obstacles, as it is doing in both videos. The algorithm can additionally handle any number of arbitrary linear constraints. On the right, for example, it is avoiding the end of the stick while staying in the yz plane.</p>"},{"location":"#extreme-pose-recovery","title":"Extreme pose recovery","text":"<p>TinyMPC can enable recovering from extreme initial conditions. In this example, it is compared against three of the Crazyflie 2.1's stock controllers. Only TinyMPC was able to keep the control inputs under the drone's limits, and the recovery looks pretty good!</p>"},{"location":"#figure-8-tracking","title":"Figure-8 tracking","text":"<p>We compared against the same stock controllers for an infeasible figure-8 tracking task (the time given to complete a single figure-8 could only be met if the drone was much more powerful). TinyMPC and PID were able to stay upright, but TinyMPC's trajectory more closely resembled a figure-8.</p>"},{"location":"algorithm/","title":"Inside TinyMPC","text":"<p>TinyMPC's trick is to precompute expensive matrices offline so that only a small amount of computation is required during operation. Our 2024 ICRA submission video provides a concise overview of the method:</p> <p>Watch the Video </p>"},{"location":"algorithm/#the-algorithm","title":"The Algorithm","text":"<p>The underlying algorithm is the alternating direction method of multipliers. TinyMPC reformulates the primal update step - the part that usually takes the longest - as an LQR problem. These have been studied for decades, and we know how to write LQR problems in a closed form: specifically, using Riccati recursion. We reorganize some of this recursive function to extract big matrices that only need to be computed once. In the vanilla implementation, this restricts TinyMPC to solving only a linear trajectory tracking problem (with any kinds of constraints, as long as they can be quickly re-linearized online). However, as seen in our demo videos, a single linearization can go a long way.</p>"},{"location":"algorithm/#alternating-direction-method-of-multipliers-admm","title":"Alternating direction method of multipliers (ADMM)","text":"<p>The alternating direction method of multipliers algorithm was developed in the 1970s and used in 2011 by researchers at Stanford to better solve the problem of distributed convex optimization. Some of these researchers later helped in developing OSQP, the Operator Splitting Quadratic Program solver. TinyMPC takes much of its inspiration from these two sources.</p> <p>We want to solve optimization problems in which our cost function \\(f\\) and set of valid states \\(\\mathcal{C}\\) are both convex:</p> \\[ \\begin{alignat}{2} \\min_x &amp; \\quad f(x) \\\\ \\text{subject to} &amp; \\quad x \\in \\mathcal{C}. \\end{alignat} \\] <p>We define an indicator function for the set \\(\\mathcal{C}\\):</p> \\[ I_\\mathcal{C}(x) = \\begin{cases} 0 &amp; x \\in \\mathcal{C} \\\\ \\infty &amp; \\text{otherwise}. \\end{cases} \\] <p>The indicator function says simply that there is infinite additional cost when \\(x\\) violates the constraints (the state \\(x\\) is outside the set of valid states \\(\\mathcal{C}\\)) and zero additional cost for obeying the constraints (\\(x\\) is inside the set \\(\\mathcal{C}\\)). Thus, we need to be able to determine whether or not a state is in the set \\(\\mathcal{C}\\) in order to know if all the constraints on our problem are being met. For speed of computation, this often takes the form \\(Hx \\geq h\\) (or \\(Hx \\leq h\\), or a combination of \\(Hx \\geq h\\) and \\(Gx \\leq g\\) (each of these can be rewritten to be equivalent to the others)). This form can describe any kind of linear constraint in \\(x\\). To do obstacle avoidance, for example, it is common to arrange \\(H\\) and \\(h\\) as half-space constraints where, in three dimensions, the entire space is split by a plane and only one half is inside the set \\(\\mathcal{C}\\). For arbitrary dimensionality, we say the space is divided by a hyperplane.</p> <p>We modify the generic optimization problem to include the indicator function by adding it to the cost. We introduce a new state variable \\(z\\), called the slack variable, to describe the constrained version of the original state variable \\(x\\), which we will now call the primal variable.</p> \\[ \\begin{alignat}{2} \\min_x &amp; \\quad f(x) + I_\\mathcal{C}(z) \\\\ \\text{subject to} &amp; \\quad x = z. \\end{alignat} \\] <p>At minimum cost, the primal variable \\(x\\) must be equal to the slack variable \\(z\\), but during each solve they will not necessarily be equal. This is because the slack variable \\(z\\) manifests in the algorithm as the version of the primal variable \\(x\\) that has been projected onto the feasible set \\(\\mathcal{C}\\), and thus whenever the primal variable \\(x\\) violates any constraint, the slack variable at that iteration will be projected back onto \\(\\mathcal{C}\\) and thus differ from \\(x\\). To push the primal variable \\(x\\) back to the feasible set \\(\\mathcal{C}\\), we introduce a third variable, \\(\\lambda\\), called the dual variable. This method is referred to as the augmented Lagrangian (originally named the method of multipliers), and introduces a scalar penalty parameter \\(\\rho\\) alongside the dual variable \\(\\lambda\\) (also known as a Lagrange multiplier). The penalty parameter \\(\\rho\\) is the augmentation to what would otherwise just be the Lagrangian of our constrained optimization problem above. \\(\\lambda\\) and \\(\\rho\\) work together to force \\(x\\) closer to \\(z\\) by increasing the cost of the augmented Lagrangian the more \\(x\\) and \\(z\\) differ.</p> \\[ \\mathcal{L}_A(x,z,\\lambda) = f(x) + I_\\mathcal{C}(z) + \\lambda^\\intercal(x-z) + \\frac{\\rho}{2}\\|x-z\\|^2_2. \\] <p>Our optimization problem has now been divided into two variables: the primal \\(x\\) and slack \\(z\\), and we can optimize over each one individually while holding all of the other variables constant. To get the ADMM algorithm, all we have to do is alternate between solving for the \\(x\\) and then for the \\(z\\) that minimizes our augmented Lagrangian. After each set of solves, we then update our dual variable \\(\\lambda\\) based on how much \\(x\\) differs from \\(z\\).</p> \\[ \\begin{alignat}{3} \\text{primal update: } &amp; x^+ &amp; ={} &amp; \\underset{x}{\\arg \\min} \\hspace{2pt} \\mathcal{L}_A(x,z,\\lambda), \\\\ \\text{slack update: } &amp; z^+ &amp; ={} &amp; \\underset{z}{\\arg \\min} \\hspace{2pt} \\mathcal{L}_A(x^+,z,\\lambda), \\\\ \\text{dual update: } &amp; \\lambda^+ &amp; ={} &amp; \\lambda + \\rho(x^+ - z^+), \\end{alignat} \\] <p>where \\(x^+\\), \\(z^+\\), and \\(\\lambda^+\\) refer to the primal, slack, and dual variables to be used in the next iteration.</p> <p>Now all we have to do is solve a few unconstrained optimization problems!</p>"},{"location":"algorithm/#todo-primal-and-slack-update-and-discrete-algebraic-riccati-equation","title":"TODO: primal and slack update and discrete algebraic riccati equation","text":""},{"location":"get-started/examples/","title":"How to Use TinyMPC","text":"<p>We offer user-friendly interfaces in high-level languages to enable low-level C++ code generation and verification, making them ready for deployment on embedded hardware. We also provide various robotic control examples, including the Crazyflie nano-quadrotor. </p> <p>Check out our GitHub repositories: Python, MATLAB, Julia</p>"},{"location":"get-started/examples/#install-the-library","title":"Install the Library","text":"PythonJuliaMATLAB <pre><code>import tinympc\nimport numpy as np\n\ntinympc_python_dir = \"/path/to/tinympc-python\"\ntinympc_dir = tinympc_python_dir + \"/tinympc/TinyMPC\"\n\nprob = tinympc.TinyMPC()\nprob.compile_lib(tinympc_dir)\n\nos_ext = \".so\" # (1)\nlib_dir = tinympc_dir + \"/build/src/tinympc/libtinympcShared\" + os_ext  # Path to the compiled library\nprob.load_lib(lib_dir)\n</code></pre> <ol> <li>Change this based on your OS! Linux: .so, Mac: .dylib, Windows: .dll</li> </ol> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre>"},{"location":"get-started/examples/#set-up-the-problem","title":"Set up the Problem","text":"<p>Check out model to learn how to obtain A and B matrices.</p> Cart-poleQuadrotor <p>For the cart-pole, we use the linearized model of the discretized cart-pole dynamics to stabilize about the upright position.</p> PythonJuliaMATLAB <pre><code>n = 4  # states: x, xdot, theta, thetadot\nm = 1  # controls: force on cart\nN = 10  # horizon\n\nA = [ # row-major order (1)\n    1, 0, 0, 0, \n    0.01, 1, 0, 0, \n    2.2330083403-5, 0.0044662105, 1.0002605176, 0.0521057900,\n    7.4430379746-8, 2.2330083403-5, 0.0100008683, 1.0002605176\n]\nB = [ # row-major order\n    7.4683685627-5,\n    0.0149367653,\n    3.7976332318-5,\n    0.0075955962\n]\n\nQ = [10.0, 1, 10, 1]  # diagonal elements in row-major order\nR = [1.0]  # diagonal elements in row-major order\nrho = 0.1  # ADMM penalty parameter\n\nx_min = [-5.0] * n * N  # state constraints\nx_max = [5.] * n * N  # state constraints\nu_min = [-5.] * m * (N - 1)  # force constraints\nu_max = [5.] * m * (N - 1)  # force constraints\n\nabs_pri_tol = 1.0e-3  # absolute primal tolerance\nabs_dual_tol = 1.0e-3  # absolute dual tolerance\nmax_iter = 100  # maximum number of iterations\ncheck_termination = 1  # how often termination conditions are checked\n\n# Setup problem data\nprob.setup(n, m, N, A, B, Q, R, x_min, x_max, u_min, u_max, rho,\n    abs_pri_tol, abs_dual_tol, max_iter, check_termination)\n</code></pre> <ol> <li>In the future, A and B will be matrices and row/column-major ordering will be handled inside prob.setup</li> </ol> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre> <p>For the quadrotor, we start with the full, continuous dynamics, then discretize and linearize about hover.</p> PythonJuliaMATLAB <pre><code>n = 4  # states: x, xdot, theta, thetadot\nm = 1  # controls: force on cart\nN = 10  # horizon\n\nA = [ # row-major order (1)\n    1, 0, 0, 0, \n    0.01, 1, 0, 0, \n    2.2330083403-5, 0.0044662105, 1.0002605176, 0.0521057900,\n    7.4430379746-8, 2.2330083403-5, 0.0100008683, 1.0002605176\n]\nB = [ # row-major order\n    7.4683685627-5,\n    0.0149367653,\n    3.7976332318-5,\n    0.0075955962\n]\n\nQ = [10.0, 1, 10, 1]  # diagonal elements in row-major order\nR = [1.0]  # diagonal elements in row-major order\nrho = 0.1  # ADMM penalty parameter\n\nx_min = [-5.0] * n * N  # state constraints\nx_max = [5.] * n * N  # state constraints\nu_min = [-5.] * m * (N - 1)  # force constraints\nu_max = [5.] * m * (N - 1)  # force constraints\n\nabs_pri_tol = 1.0e-3  # absolute primal tolerance\nabs_dual_tol = 1.0e-3  # absolute dual tolerance\nmax_iter = 100  # maximum number of iterations\ncheck_termination = 1  # how often termination conditions are checked\n\n# Setup problem data\nprob.setup(n, m, N, A, B, Q, R, x_min, x_max, u_min, u_max, rho,\n    abs_pri_tol, abs_dual_tol, max_iter, check_termination)\n</code></pre> <ol> <li>In the future, A and B will be matrices and row/column-major ordering will be handled inside prob.setup</li> </ol> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre>"},{"location":"get-started/examples/#generate-solver-code","title":"Generate Solver Code","text":"<p>We generated low-level C++ code ready for deployment on embedded hardware.</p> PythonJuliaMATLAB <pre><code>output_dir = tinympc_python_dir + \"/generated_code\"  # Path to the generated code\nprob.tiny_codegen(tinympc_dir, output_dir)\nprob.compile_lib(output_dir)\n\nprob.load_lib(output_dir + \"/build/tinympc/libtinympcShared\" + os_ext)  # Load the library\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre>"},{"location":"get-started/examples/#interact-with-solver-code","title":"Interact with Solver Code","text":"<p>We can also verify our program by interacting in high-level languages before deployment. This naturally provides a convenient software-in-the-loop (SIL) testing pipeline. Below is an example of running MPC in simulation, you can use any simulators.</p> PythonJuliaMATLAB <pre><code>x = [0.0] * n * N  # Initial state\nu = [0.0] * m * (N - 1)  # List of control inputs in horizon\nx_all = []  # List of all stored states\nx_noise = x * 1\n# Matrices for simulation\nAnp = np.array(A).reshape((n, n)).transpose()\nBnp = np.array(B).reshape((n, m))\n\nprint(\"=== START INTERACTIVE MPC ===\")\n\nNSIM = 300\nfor i in range(NSIM):\n    # 1. Set initial state from measurement    \n    prob.set_x0(x_noise, 0)  # Set initial state to C code\n\n    # 2. Set the reference state if needed    \n\n    # 3. Solve the problem\n    prob.solve(0)  # Call the solve in C code\n\n    # 4. Get the control input\n    prob.get_u(u, 0)  # Get the control input from C code\n\n    # 5. Simulate the dynamics    \n    x = Anp@np.array(x).reshape((n, 1))+ Bnp*np.array(u[0]) \n\n    noise = np.random.normal(0, 0.01, (n, 1))\n    x_noise = x + noise\n    # print(f\"X = {x}\")\n    x = x.reshape(n).tolist() \n    x_noise = x_noise.reshape(n).tolist() \n    # print(f\"X = {x}\")\n    x_all.append(x)\n\nprint((x_all))\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre>"},{"location":"get-started/model/","title":"Model","text":""},{"location":"get-started/model/#linearization","title":"Linearization","text":"<p>TinyMPC in its vanilla implementation can only handle linear dynamics, which means systems must be linearized about an equilibrium before being used by the solver. Extensions to TinyMPC allow the user to approximate a system's nonlinear dynamics by storing multiple linearizations, but we will start with only one.</p> <p>A discrete, linearized system is of the form \\(x_{k+1} = Ax_k + Bu_k\\), where \\(x_k\\) and \\(u_k\\) are the state and control at the current time step, \\(A\\) is the state-transition matrix, \\(B\\) is the control or input matrix, and \\(x_{k+1}\\) is the state at the next time step. For each of the examples given in the previous page, the state-transition matrix \\(A\\) and input matrix \\(B\\) were computed from the system's continuous, nonlinear dynamics. (1)</p> <ol> <li>The system still needs to be discretized even if it is already linear. This can be done with the matrix exponential or by the same methods shown for the nonlinear system below.</li> </ol>"},{"location":"get-started/model/#cart-pole-example","title":"Cart-pole example","text":"<p>The continuous time dynamics for the cart-pole have been derived many times. For this example we'll use the convention from this derivation, where the pole is upright at \\(\\theta=0\\). If we ignore friction for this model, the only equations we care about in that derivation are (23) and (24). (1)</p> <ol> <li>If you're following along and want to use a cart-pole model that has friction, use equations (21) and (22).</li> </ol> <p>Let's write those down in a dynamics function</p> PythonJulia <pre><code>mc = 0.2 # mass of the cart (kg)\nmp = 0.1 # mass of the pole (kg)\n\u2113 = 0.5 # distance to the center of mass (meters)\ng = 9.81\n# (1)\n\ndef cartpole_dynamics(x, u):\n    r       = x[0] # cart position\n    theta   = x[1] # pole angle\n    rd      = x[2] # change in cart position\n    theta_d = x[3] # change in pole angle\n    F       = u[0] # force applied to cart\n\n    theta_dd = (g*np.sin(theta) + np.cos(theta) * ((-F - mp*l*(theta_d**2) * \\\n                    np.sin(theta))/(mc + mp))) / (l*(4/3 - (mp*(np.cos(theta)**2))/(mc + mp)))\n    rdd = (F + mp*l*((theta_d**2)*np.sin(theta) - theta_dd*np.cos(theta))) / (mc + mp)\n\n    return np.array([rd, theta_d, rdd, theta_dd])\n</code></pre> <ol> <li>Good practice would be to add an argument to \\(\\text{cartpole_dynamics}\\) that stores each of these parameters.</li> </ol> <pre><code>mc = 0.2 # mass of the cart (kg)\nmp = 0.1 # mass of the pole (kg)\n\u2113 = 0.5 # distance to the center of mass (meters)\ng = 9.81\n# (1)\n\nfunction cartpole_dynamics(x::Vector, u::Vector)\n    r  = x[1] # cart position\n    \u03b8  = x[2] # pole angle\n    rd = x[3] # change in cart position\n    \u03b8d = x[4] # change in pole angle\n    F  = u[1] # force applied to cart\n\n    \u03b8dd = (g*sin(\u03b8) + cos(\u03b8) * ((-F - mp*\u2113*(\u03b8d^2) * sin(\u03b8))/(mc + mp))) /\n             (\u2113*(4/3 - (mp*(cos(\u03b8)^2))/(mc + mp)))\n    rdd = (F + mp*\u2113*((\u03b8d^2)*sin(\u03b8) - \u03b8dd*cos(\u03b8))) / (mc + mp)\n\n    return [rd; \u03b8d; rdd; \u03b8dd]\nend\n</code></pre> <ol> <li>Good practice would be to add an argument to \\(\\text{cartpole_dynamics}\\) that stores each of these parameters.</li> </ol> <p>This function describes the continuous (nonlinear) dynamics of our system, i.e. \\(\\dot{x} = \\text{cartpole_dynamics}(x, u)\\). Before linearizing, we first discretize our continuous dynamics with an integrator. RK4 (Runge-Kutta 4th order) is a common explicit integrator, but you can write down whatever you like.</p> PythonJulia <pre><code>def cartpole_rk4(x, u, dt):\n    f1 = dt*cartpole_dynamics(x, u)\n    f2 = dt*cartpole_dynamics(x + f1/2, u)\n    f3 = dt*cartpole_dynamics(x + f2/2, u)\n    f4 = dt*cartpole_dynamics(x + f3, u)\n    return x + (1/6)*(f1 + 2*f2 + 2*f3 + f4)\n</code></pre> <pre><code>function cartpole_rk4(x::Vector, u::Vector, dt::Float64)\n    f1 = dt*cartpole_dynamics(x, u)\n    f2 = dt*cartpole_dynamics(x + f1/2, u)\n    f3 = dt*cartpole_dynamics(x + f2/2, u)\n    f4 = dt*cartpole_dynamics(x + f3, u)\n    return x + (1/6)*(f1 + 2*f2 + 2*f3 + f4)\nend\n</code></pre> <p>Our integrator takes in the state and control at the current time step and integrates the state forward by \\(\\Delta t\\) seconds (the dt parameter in the RK4 function). We now have the discrete (nonlinear) dynamics of our system, defined by \\(x_{k+1} = \\text{cartpole_rk4}(x_k, u_k, dt)\\). Now, we linearize about an equilibrium position to obtain state-transition and input matrices \\(A\\) and \\(B\\) we described earlier. Differentiating \\(\\text{cartpole_rk4}\\) by hand would be a pain, but luckily we have access to automatic differentiation tools to do this for us.</p> PythonJulia <pre><code>import autograd as AG\n\nxgoal = np.array([0.0, np.pi, 0.0, 0.0])\nugoal = np.array([0.0])\n\ndt = 0.01\n\nA = AG.jacobian(lambda x_: cartpole_rk4(x_, ugoal))(xgoal)\nB = AG.jacobian(lambda u_: cartpole_rk4(xgoal, u_))(ugoal)\n</code></pre> <pre><code>import ForwardDiff as FD\n\nxgoal = [0; pi; 0; 0]\nugoal = [0]\n\ndt = 0.01\n\nA = FD.jacobian(dx -&gt; cartpole_rk4(params, dx, ugoal, dt), xgoal)\nB = FD.jacobian(du -&gt; cartpole_rk4(params, xgoal, du, dt), ugoal)\n</code></pre> <p>Now all you have to do is save \\(A\\) and \\(B\\) and pass them to TinyMPC as shown in the problem setup section of the examples page.</p>"}]}